{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以图搜图\n",
    "\n",
    "本 Notebook 将引导您完成设置和使用基于 Amazon OpenSearch 的图像搜索系统的全过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境准备\n",
    "\n",
    "首先，我们需要创建一个python环境并安装所需的依赖项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 安装依赖项\n",
    "!pip install boto3 opensearch-py requests_aws4auth numpy tqdm opencv-python pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 设置环境变量\n",
    "\n",
    "接下来，我们需要设置一些环境变量，这些变量将在后续步骤中使用。\n",
    "\n",
    "**【注意】**：'ImgSearch' role 需要预先创建好，建议给予SageMakerFullAccess 和 aoss:*，BedrockFullAccess权限。另外需要在bedrock的model access中打开各类embedding模型的权限"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 设置环境变量\n",
    "OPENSEARCH_INDEX_NAME = 'image-index'\n",
    "OPENSEARCH_COLLECTION_NAME = 'image-search-collection'\n",
    "REGION = 'us-west-2'\n",
    "\n",
    "# The S3 bucket for the coresponding SageMaker \n",
    "BUCKET_NAME = 'sagemaker-us-west-2-687752207838'\n",
    "\n",
    "EMBEDDING_LENGTH = 256\n",
    "EMBEDDING_MODEL_ID = 'amazon.titan-embed-image-v1'\n",
    "\n",
    "# The SageMaker Execution Role Name\n",
    "ROLE_NAME = 'ImgSearch'\n",
    "\n",
    "# The policies on aoss side\n",
    "encryption_policy_name = 'image-search-encryption-policy'\n",
    "network_policy_name = 'image-search-network-policy'\n",
    "access_policy_name = 'image-search-access-policy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 创建 OpenSearch Serverless Collection\n",
    "\n",
    "现在，我们将创建一个 OpenSearch Serverless Collection，用于存储图像嵌入向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from requests_aws4auth import AWS4Auth\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "\n",
    "boto3.set_stream_logger('boto3.resources', logging.DEBUG)\n",
    "# AWS 配置\n",
    "region = REGION  # 例如 'us-west-2'\n",
    "service = 'aoss'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "\n",
    "awsauth = AWSV4SignerAuth(credentials, region, \"aoss\")\n",
    "\n",
    "# OpenSearch Serverless 客户端\n",
    "aoss_client = boto3.client(service_name=\"opensearchserverless\", region_name=REGION)\n",
    "\n",
    "role_arn = f\"arn:aws:iam::{boto3.client('sts').get_caller_identity()['Account']}:role/{ROLE_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建加密策略\n",
    "try:\n",
    "    security_policy = aoss_client.create_security_policy(\n",
    "        name = encryption_policy_name,\n",
    "        policy = json.dumps(\n",
    "            {\n",
    "                'Rules': [{'Resource': ['collection/' + OPENSEARCH_COLLECTION_NAME],\n",
    "                'ResourceType': 'collection'}],\n",
    "                'AWSOwnedKey': True\n",
    "            }),\n",
    "        type = 'encryption'\n",
    "    )\n",
    "    print(f\"创建加密策略: {encryption_policy_name}\")\n",
    "except aoss_client.exceptions.ConflictException:\n",
    "    print(f\"加密策略 {encryption_policy_name} 已存在\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建网络策略\n",
    "try:\n",
    "    network_policy = aoss_client.create_security_policy(\n",
    "        name = network_policy_name,\n",
    "        policy = json.dumps(\n",
    "            [\n",
    "                {'Rules': [{'Resource': ['collection/' + OPENSEARCH_COLLECTION_NAME],\n",
    "                'ResourceType': 'collection'}],\n",
    "                'AllowFromPublic': True}\n",
    "            ]),\n",
    "        type = 'network'\n",
    "    )\n",
    "    print(f\"创建网络策略: {network_policy_name}\")\n",
    "except aoss_client.exceptions.ConflictException:\n",
    "    print(f\"网络策略 {network_policy_name} 已存在\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建访问策略\n",
    "try:\n",
    "    access_policy = aoss_client.create_access_policy(\n",
    "        name = access_policy_name,\n",
    "        policy = json.dumps(\n",
    "        [\n",
    "            {\n",
    "                'Rules': [\n",
    "                    {\n",
    "                        'Resource': ['collection/' + OPENSEARCH_COLLECTION_NAME],\n",
    "                        'Permission': [\n",
    "                            'aoss:CreateCollectionItems',\n",
    "                            'aoss:DeleteCollectionItems',\n",
    "                            'aoss:UpdateCollectionItems',\n",
    "                            'aoss:DescribeCollectionItems',\n",
    "                        ],\n",
    "                        'ResourceType': 'collection'\n",
    "                    },\n",
    "                    {\n",
    "                        'Resource': ['index/' + '*' + '/*'],\n",
    "                        'Permission': [\n",
    "                            'aoss:CreateIndex',\n",
    "                            'aoss:DeleteIndex',\n",
    "                            'aoss:UpdateIndex',\n",
    "                            'aoss:DescribeIndex',\n",
    "                            'aoss:ReadDocument',\n",
    "                            'aoss:WriteDocument',\n",
    "                        ],\n",
    "                        'ResourceType': 'index'\n",
    "                    }\n",
    "                ],\n",
    "                'Principal': [role_arn],\n",
    "                'Description': 'Complete data access policy'\n",
    "            }\n",
    "        ]),\n",
    "        type = 'data'\n",
    "    )\n",
    "\n",
    "    print(f\"创建访问策略: {access_policy_name}\")\n",
    "except aoss_client.exceptions.ConflictException:\n",
    "    print(f\"访问策略 {access_policy_name} 已存在\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 等待策略生效\n",
    "print(\"等待策略生效...\")\n",
    "time.sleep(10)\n",
    "print(\"继续执行...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建集合\n",
    "collection_name = OPENSEARCH_COLLECTION_NAME\n",
    "try:\n",
    "    response = aoss_client.create_collection(\n",
    "        name=collection_name,\n",
    "        type='VECTORSEARCH'\n",
    "    )\n",
    "    print(f\"集合已创建: {response['createCollectionDetail']['name']}\")\n",
    "except aoss_client.exceptions.ConflictException:\n",
    "    print(f\"集合 {collection_name} 已存在\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 等待集合变为活动状态\n",
    "print(\"等待集合变为活动状态...\")\n",
    "while True:\n",
    "    status = aoss_client.list_collections(collectionFilters={'name':OPENSEARCH_COLLECTION_NAME})['collectionSummaries'][0]['status']\n",
    "    print(f\"当前状态: {status}\")\n",
    "    if status in ('ACTIVE', 'FAILED'):\n",
    "        break\n",
    "    time.sleep(10)\n",
    "\n",
    "print(f\"集合 {collection_name} 已激活\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 获取集合端点\n",
    "collection = aoss_client.list_collections(collectionFilters={'name':OPENSEARCH_COLLECTION_NAME})['collectionSummaries'][0]\n",
    "\n",
    "collection_arn = collection['arn']\n",
    "collection_id = collection['id']\n",
    "\n",
    "host = collection_id + '.' + region + '.aoss.amazonaws.com'\n",
    "print(f\"OpenSearch 端点: {host}\")\n",
    "\n",
    "# 创建 OpenSearch 客户端\n",
    "os_client = OpenSearch(hosts=[{'host': host, 'port': 443}], http_auth=awsauth, use_ssl=True, verify_certs=True, connection_class=RequestsHttpConnection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建索引\n",
    "\n",
    "index_body = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"pic_emb\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": EMBEDDING_LENGTH,\n",
    "                \"similarity\": \"cosine\",\n",
    "                \"method\": {\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"engine\": \"faiss\"\n",
    "                }\n",
    "            },\n",
    "            \"s3_uri\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"pic_name\":  { \n",
    "                \"type\" : \"keyword\" \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "if not os_client.indices.exists(index=OPENSEARCH_INDEX_NAME):\n",
    "    try:\n",
    "        os_client.indices.create(index=OPENSEARCH_INDEX_NAME, body=index_body)\n",
    "        print(f\"索引 {OPENSEARCH_INDEX_NAME} 已创建\")\n",
    "    except Exception as e:\n",
    "        print(f\"异常：{e}， 请注意当前role是否能操作OpenSearch Serverless\")\n",
    "else:\n",
    "    print(f\"索引 {OPENSEARCH_INDEX_NAME} 已存在\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 导入数据到 OpenSearch\n",
    "\n",
    "现在，我们将导入图像数据到 OpenSearch。首先，我们需要定义一些辅助函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "import boto3\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, helpers\n",
    "from requests_aws4auth import AWS4Auth\n",
    "import cv2\n",
    "import os\n",
    "import base64\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# 定义常量\n",
    "MAX_IMAGE_HEIGHT: int = 2048\n",
    "MAX_IMAGE_WIDTH: int = 2048\n",
    "\n",
    "# 创建 Bedrock 客户端\n",
    "bedrock = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义获取嵌入向量的函数\n",
    "def getEmbeddings(inputImageB64, max_retries=10, initial_delay=2, text=None, output_embedding_length=1024):\n",
    "    def exponential_delay(attempt):\n",
    "        return initial_delay * (2 ** attempt)\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            request_body = {\n",
    "                \"inputText\": text,\n",
    "                \"inputImage\": inputImageB64,\n",
    "                \"embeddingConfig\": {\n",
    "                    \"outputEmbeddingLength\": output_embedding_length\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            body = json.dumps(request_body)\n",
    "            response = bedrock.invoke_model(\n",
    "                body=body,\n",
    "                modelId=EMBEDDING_MODEL_ID,\n",
    "                accept=\"application/json\",\n",
    "                contentType=\"application/json\")\n",
    "            response_body = json.loads(response.get(\"body\").read())\n",
    "            return np.array([response_body.get(\"embedding\")]).astype(np.float32)\n",
    "        except ClientError as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise  # If this was the last attempt, re-raise the exception\n",
    "\n",
    "            delay = exponential_delay(attempt)\n",
    "            print(f\"{e}\")\n",
    "            print(f\"请求失败。{delay} 秒后重试...\")\n",
    "            time.sleep(delay)\n",
    "        \n",
    "    # If we've exhausted all retries\n",
    "    raise Exception(\"达到最大重试次数。无法获取嵌入向量。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义图像处理函数\n",
    "def resizeandGetByteData(imageFile):\n",
    "    image = Image.open(imageFile)\n",
    "    if (image.size[0] * image.size[1]) > (MAX_IMAGE_HEIGHT * MAX_IMAGE_WIDTH):\n",
    "        image = image.resize((MAX_IMAGE_HEIGHT, MAX_IMAGE_WIDTH))\n",
    "    with BytesIO() as output:\n",
    "        image.save(output, 'png')\n",
    "        bytes_data = output.getvalue()\n",
    "    return bytes_data\n",
    "\n",
    "def embed_img(img_patch_pair, preprocessing_img_dir, text=None, output_embedding_length=1024):\n",
    "    \"\"\"处理单个图像并返回嵌入向量和图像名\"\"\"\n",
    "    try:\n",
    "        image_name, patch_name = img_patch_pair[0], img_patch_pair[1]\n",
    "\n",
    "        patch_path = os.path.join(preprocessing_img_dir, patch_name)\n",
    "        with open(patch_path, 'rb') as f:\n",
    "            bytes_data = resizeandGetByteData(f)\n",
    "            input_image_base64 = base64.b64encode(bytes_data).decode('utf-8')\n",
    "            embedding = getEmbeddings(input_image_base64, text=text, output_embedding_length=output_embedding_length)[0]\n",
    "            return (image_name, patch_name, embedding, None)\n",
    "    except Exception as e:\n",
    "        return (image_name, patch_name, None, str(e))\n",
    "\n",
    "def process_embeddings_unordered(img_patch_pairs, preprocessing_img_dir, output_embedding_length=1024):\n",
    "    \"\"\"乱序处理，按名称重排序对齐结果\"\"\"\n",
    "    # 存储所有结果和失败记录\n",
    "    failed_entries = []\n",
    "    \n",
    "    # 按原始输入顺序重建结果列表\n",
    "    embeddings = []\n",
    "    pairs = []\n",
    "    \n",
    "    documents = []\n",
    "\n",
    "    # 动态线程数（I/O密集型任务可增加）\n",
    "    max_workers = min(32, (os.cpu_count() or 1) * 4)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # 提交所有任务\n",
    "        futures = {\n",
    "            executor.submit(embed_img, pair, preprocessing_img_dir, None, output_embedding_length): pair\n",
    "            for pair in img_patch_pairs\n",
    "        }\n",
    "        \n",
    "        # 使用tqdm跟踪进度\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"处理中\"):\n",
    "            image_id, patch_name, embedding, error = future.result()\n",
    "            if error:\n",
    "                print(f'错误: {error}')\n",
    "                failed_entries.append((image_id, patch_name, error))\n",
    "            else:\n",
    "                if embedding is not None:\n",
    "                    embeddings.append(embedding)\n",
    "                    pairs.append((image_id, patch_name))\n",
    "                    image_name = image_id.split('/')[-1]\n",
    "                    documents.append({\n",
    "                        \"s3_uri\": f\"s3://{BUCKET_NAME}/{image_name}\",\n",
    "                        \"pic_emb\": embedding,\n",
    "                        \"pic_name\": image_name\n",
    "                    })\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_connected_components(image_path, output_dir=\"object_patches\", min_size=(20, 20)):\n",
    "    \"\"\"\n",
    "    将图像中的非透明区域分割为独立的透明背景 Patch\n",
    "    \"\"\"\n",
    "    img_patch_pairs = []\n",
    "    \n",
    "    img_name_without_ext = Path(image_path).stem\n",
    "    \n",
    "    # 创建输出目录\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 读取图像并保留透明通道（BGRA 格式）\n",
    "    img_bgra = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    if img_bgra is None:\n",
    "        raise FileNotFoundError(f\"无法加载图像: {image_path}\")\n",
    "    \n",
    "    # 提取 Alpha 通道并二值化（非透明区域为白色）\n",
    "    alpha_channel = img_bgra[:, :, 3]\n",
    "    _, binary_mask = cv2.threshold(alpha_channel, 1, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 检测连通区域\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_mask)\n",
    "    \n",
    "    # 遍历每个连通区域（跳过背景标签 0）\n",
    "    for idx, label in enumerate(range(1, num_labels)):\n",
    "        # 获取当前区域的统计信息\n",
    "        x, y, w, h = stats[label][cv2.CC_STAT_LEFT], \\\n",
    "                     stats[label][cv2.CC_STAT_TOP], \\\n",
    "                     stats[label][cv2.CC_STAT_WIDTH], \\\n",
    "                     stats[label][cv2.CC_STAT_HEIGHT]\n",
    "        \n",
    "        if w < min_size[0] and h < min_size[1]:\n",
    "            continue\n",
    "        # 裁剪当前区域（包括透明背景）\n",
    "        patch_bgra = img_bgra[y:y+h, x:x+w]\n",
    "        \n",
    "        # 创建透明背景的 Patch（确保 Alpha 通道正确）\n",
    "        patch_rgba = cv2.cvtColor(patch_bgra, cv2.COLOR_BGRA2RGBA)\n",
    "        \n",
    "        patch_pil = Image.fromarray(patch_rgba)\n",
    "        \n",
    "        patch_img_name = f'{img_name_without_ext}_{idx}.png'\n",
    "        img_patch_pairs.append((image_path, patch_img_name))\n",
    "        # 保存为 PNG\n",
    "        patch_pil.save(os.path.join(output_dir, patch_img_name))\n",
    "    \n",
    "    return img_patch_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义导入数据的函数\n",
    "def import_data_to_opensearch(image_dir):\n",
    "    # 创建 S3 客户端\n",
    "    s3 = boto3.client('s3')\n",
    "    bucket = BUCKET_NAME\n",
    "    index_name = OPENSEARCH_INDEX_NAME\n",
    "    embedding_length = EMBEDDING_LENGTH\n",
    "    \n",
    "    # 创建临时目录存储处理后的图像\n",
    "    preprocessing_img_dir = \"object_patches\"\n",
    "    os.makedirs(preprocessing_img_dir, exist_ok=True)\n",
    "\n",
    "    img_patch_pairs = []\n",
    "    \n",
    "    # 获取所有图片\n",
    "    image_list = os.listdir(image_dir)\n",
    "    image_list = [Path(img).name for img in image_list if img.endswith('.jpg') or img.endswith('.webp') or img.endswith('.png') or \n",
    "                  img.endswith('.jpeg') or img.endswith('.JPG') or img.endswith('.PNG') or img.endswith('.JPEG')]\n",
    "    image_list = image_list[:20]  # 限制处理的图像数量\n",
    "    \n",
    "    print(f\"找到 {len(image_list)} 张图像\")\n",
    "    \n",
    "    # 处理图像，分割连通区域\n",
    "    with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "        futures = {\n",
    "            executor.submit(split_connected_components, os.path.join(image_dir, k), preprocessing_img_dir): k\n",
    "            for k in image_list\n",
    "        }\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"裁剪连通区域\"):\n",
    "            try:\n",
    "                img_patch_pairs += future.result()            \n",
    "            except Exception as e:\n",
    "                print(f\"处理图像时出错: {e}\")\n",
    "    \n",
    "    print(f\"共生成 {len(img_patch_pairs)} 个图像块\")\n",
    "    \n",
    "    # 为所有图像生成嵌入向量\n",
    "    documents = process_embeddings_unordered(\n",
    "        img_patch_pairs, \n",
    "        preprocessing_img_dir,\n",
    "        output_embedding_length=embedding_length\n",
    "    )\n",
    "    \n",
    "    print(f\"生成了 {len(documents)} 个文档\")\n",
    "    \n",
    "    # 上传图像到 S3\n",
    "    for image_name in tqdm(image_list, desc=\"上传图像到 S3\"):\n",
    "        s3.upload_file(os.path.join(image_dir, image_name), bucket, image_name)\n",
    "    \n",
    "    # 批量导入到 OpenSearch\n",
    "    actions = [\n",
    "        {\n",
    "            \"_index\": index_name,\n",
    "            \"_source\": document\n",
    "        }\n",
    "        for document in documents\n",
    "    ]\n",
    "    \n",
    "    print(\"导入数据到 OpenSearch...\")\n",
    "    helpers.bulk(os_client, actions, request_timeout=300)\n",
    "    print(\"数据导入完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注入本地路径的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data_to_opensearch('./imgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 测试效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_by_aos_knn(os_client, q_embedding, index_name, size=10):\n",
    "    #Note: 查询时无需指定排序方式，最临近的向量分数越高，做过归一化(0.0~1.0)\n",
    "    #精准Knn的查询语法参考 https://opensearch.org/docs/latest/search-plugins/knn/knn-score-script/\n",
    "    #模糊Knn的查询语法参考 https://opensearch.org/docs/latest/search-plugins/knn/approximate-knn/\n",
    "    #这里采用的是模糊查询\n",
    "    query = {\n",
    "        \"size\": size,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"pic_emb\": {\n",
    "                    \"vector\": q_embedding,\n",
    "                    \"k\": size\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    opensearch_knn_respose = []\n",
    "    query_response = os_client.search(\n",
    "        body=query,\n",
    "        index=index_name\n",
    "    )\n",
    "    opensearch_knn_respose = [{'score':item['_score'],'s3_uri':item['_source']['s3_uri'], 'pic_name':item['_source']['pic_name']}  for item in query_response[\"hits\"][\"hits\"]]\n",
    "    return opensearch_knn_respose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_image_path='./object_patches/Picture1_3.png'\n",
    "with open(query_image_path, 'rb') as f:\n",
    "    bytes_data = f.read()\n",
    "    input_image_base64 = base64.b64encode(bytes_data).decode('utf-8')\n",
    "    embedding = getEmbeddings(input_image_base64, text=None, output_embedding_length=EMBEDDING_LENGTH)[0]\n",
    "\n",
    "opensearch_knn_respose = search_by_aos_knn(os_client=os_client, q_embedding=embedding, index_name=OPENSEARCH_INDEX_NAME, size=10)\n",
    "for result in opensearch_knn_respose:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
